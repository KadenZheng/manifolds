{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup and Test Environment\n",
        "\n",
        "This notebook helps you set up your environment and test that everything is working correctly.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. Install required packages:\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "2. Set up your Hugging Face token:\n",
        "   - Copy `.env.example` to `.env`\n",
        "   - Add your Hugging Face token to the `.env` file\n",
        "   - Get a token from: https://huggingface.co/settings/tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test environment setup\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path if needed\n",
        "project_root = Path.cwd().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Check if .env file exists\n",
        "env_path = project_root / '.env'\n",
        "if not env_path.exists():\n",
        "    print(\"❌ .env file not found!\")\n",
        "    print(\"   Please copy .env.example to .env and add your HuggingFace token\")\n",
        "else:\n",
        "    print(\"✅ .env file found\")\n",
        "    \n",
        "# Load environment variables\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Check if token is set\n",
        "hf_token = os.getenv('HF_TOKEN')\n",
        "if not hf_token or hf_token == 'your_hugging_face_token_here':\n",
        "    print(\"❌ HF_TOKEN not properly set in .env file\")\n",
        "    print(\"   Please add your actual Hugging Face token\")\n",
        "else:\n",
        "    print(\"✅ HF_TOKEN is set\")\n",
        "    print(f\"   Token starts with: {hf_token[:10]}...\")\n",
        "    \n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Environment variables loaded from .env:\")\n",
        "print(f\"  MODEL_NAME: {os.getenv('MODEL_NAME', 'Not set')}\")\n",
        "print(f\"  BATCH_SIZE: {os.getenv('BATCH_SIZE', 'Not set')}\")\n",
        "print(f\"  DEVICE: {os.getenv('DEVICE', 'Not set')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Model Loading\n",
        "\n",
        "Now let's test if we can successfully load the model with your token:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test model loading\n",
        "from src import Config, load_model_and_tokenizer\n",
        "\n",
        "print(\"Testing model loading...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    # Create configuration\n",
        "    config = Config()\n",
        "    print(f\"Configuration created\")\n",
        "    print(f\"  Model: {config.model_name}\")\n",
        "    print(f\"  Device: {config.device}\")\n",
        "    print(f\"  Batch size: {config.batch_size}\")\n",
        "    \n",
        "    # Try to load model\n",
        "    print(\"\\nLoading model and tokenizer...\")\n",
        "    model, tokenizer = load_model_and_tokenizer(config)\n",
        "    \n",
        "    print(\"\\n✅ SUCCESS! Model loaded successfully\")\n",
        "    print(f\"  Model layers: {model.config.num_hidden_layers}\")\n",
        "    print(f\"  Hidden size: {model.config.hidden_size}\")\n",
        "    print(f\"  Vocabulary size: {model.config.vocab_size}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERROR loading model: {e}\")\n",
        "    print(\"\\nPossible solutions:\")\n",
        "    print(\"1. Make sure your HF_TOKEN is valid\")\n",
        "    print(\"2. Check that you have access to Llama-3.2-1B on Hugging Face\")\n",
        "    print(\"3. Try running: huggingface-cli login\")\n",
        "    print(\"4. Check your internet connection\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "If everything is working:\n",
        "1. You can now run any of the analysis notebooks\n",
        "2. Start with `analysis/pca/llama_multilayer_pca_clean.ipynb` for the main PCA analysis\n",
        "3. Try `analysis/circle_fitting/circle_fitting.ipynb` for the circle fitting experiment\n",
        "4. View results in `results/html/index.html`\n",
        "\n",
        "If you had errors:\n",
        "1. Make sure you've added your actual HuggingFace token to `.env`\n",
        "2. Ensure you have access to Llama-3.2-1B model on HuggingFace\n",
        "3. Check that all requirements are installed: `pip install -r requirements.txt`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
